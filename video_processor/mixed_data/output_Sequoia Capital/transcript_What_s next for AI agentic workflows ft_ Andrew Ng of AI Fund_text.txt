 All of you know Andrew, as a famous computer science professor at Stanford, was really early on in the development of neural networks with GPUs. Of course, a creator of Coursera and popular courses like deep learning.ai, also the founder and creator and early lead of Google Brain. But one thing I've always wanted to ask you before I handed over Andrew while you're on stage is a question I think would be relevant to the whole audience. 10 years ago, on problem set number two of CS229, you gave me a B. And I was wondering, I looked it over, I was wondering what you saw that I didn't correctly. So anyway, Andrew. Thank you, Hansine. Looking forward to sharing with all of you what I'm seeing with AI agents, which I think is an exciting trend that I think everyone building an AI should pay attention to. And I'm also excited about all the other was next presentations. So AI agents, today the way most of us use large language models is like this, with a non-agent workload where you type a prompt and generate an answer. And that's a bit like if you are a person to write an essay on a topic and I say please sit down and keep on it and just type the essay from start to finish with whatever using backspace. And despite how hard this is, LMS do it remarkably well. In contrast, within a gentic workflow, this is what it may look like. Have an AI, have a LMS, say write an essay online. Do you need to do any web research? So let's do that. Then write the first draft and then meet your own draft and think about what pods need revision. And then revise your draft and you go on and on. And so this workflow is much more iterative where you may have the LMS do some thinking and then revise this article and then do some more thinking and iterate this through a number of times. And what not many people appreciate is this delivers remarkably better results. I've actually really surprised myself working these agent workflows, how well they work. I'm going to do one case study at my team analyze some data using a coding benchmark called a human e-vow benchmark released by opening it a few years ago. But this says coding problems like given the non-antilistic integers, returns some of all the all elements or even positions. And it turns out the answer is code snippet like that. So today, a lot of us will use zero-shot prompting, meaning we told the AI write the code and have it run on the first spot. Like who calls like that? No human calls like that. We just type out the code and run it. Maybe you do. I can't do that. So it turns out that if you use GPT3.5, zero-shot prompting, it gets it 48% right, GPT4 way better, 67% right. But if you take an agent workflow and wrap it around GPT3.5, say it actually does better than even GPT4. And if you were to wrap this type of workflow around GPT4, it also does very well. And you notice that GPT3.5 with an agent workflow actually upperforms GPT4. And I think this means that this is a secret consequences, I think how we all approach building applications. So agents is the terms that are in toss around a lot. There's a lot of consultant reports, how about agents, the future of AI, blah, blah, blah. I want to be a bit concrete and share of you the broad design patterns I'm seeing in agents. And I think that's a very messy chaotic space. Tons of research, tons of organizations, there's a lot going on, but I try to categorize a bit more concretely what's going on in agents. Refection is a tool that I think many of us just use. It just works. To use, I think it's more widely appreciated, but actually works pretty well. I think of this as pretty robust technologies. When I use them, I can almost always get them to work well. Planning and multi-agent collaboration, I think it is more emerging. When I use them, sometimes my mind is blown for how well they work. But at least at this moment in time, I don't feel like I can always get them to work reliably. So let me walk through these four design patterns in a few slides. And if some of you go back and yourself will ask your engineers to use these, I think you get the productivity boost quite quickly. So reflection, here's an example. Let's say I ask a system, please write code for me for a given toss, then we have a colder agent, just an LAM that you prompt to write code, to say, you know, deaf, do, toss, write a function like that. An example of self-reflection would be if you then prompt the LAM with something like this, here's code intended for a toss and just give it back the exact same code that it just generated. And then say check the code carefully for correctness, sign efficiency, good construction for them, just write it properly like that. It turns out the same LAM that you prompted to write the code, may be able to spot problems like this bug in line 5, we have fixed it by blah, blah, blah. And if you now take your own feedback and give it to it and reprompt it, it may come up with a version two of the code that could work better than the first version, not guarantee, but it works, you know, often enough for this to be worth trying for a lot of applications. To foreshadow two use, if you let it run unit tests, if it fails a unit test, then it shows why you fail the unit test, have that conversation, and maybe to figure out, fail the unit test, so you try changing something and come up with V3. By the way, for those of you that want to learn more about these technologies, I'm very excited about them, for each of the four sections have a little recommended reading section in the bottom that, you know, hopefully gives more references. And again, just to foreshadow multi-agent systems, I've described as a single code agent that you prompt to have it, you know, have this conversation of itself. One natural evolution of this idea is instead of a single code agent, you can have two agents, one is a code agent, and the second is a critic agent, and these could be the same base LM model, but they you prompt in different ways, we say one, your expert code or write code, you'll say your expert code reviewer is a reviewer's code, and this have a workflow is actually pretty easy to implement. I think it's a very general purpose technology for a lot of workflows, this would give you a significant boost in the performance of LMS. The second design pattern is to use, many of you already have seen LM-based systems using tools on the left, this is screenshot from co-pilot on the right, this is something that I kind of extracted from GPT-4, but you know, LMS today, if you ask it, what's the best copy maker, your web search, for some problems, LMS will generate code and run codes, and it turns out that there are a lot of different tools that many different people are using for analysis, for gathering information, for taking action, for personal productivity. It turns out a lot of the early work on two years turned out to be in the computer vision community, because before large language models, LMS, you know, they couldn't do anything with images, so the only option was to the LM generate a function called, they could manipulate an image, like generate an image, or do object detection, or whatever, so if you actually look at literature, it's interesting how much of the work in two years seems like an originator from vision, because LMS will blind the images before GPT-4D and lava, and so on, so that's to use, and it expands what an LM can do. And in planning, for those of you that have not yet played a lot with planning algorithms, I feel like a lot of people talk about the chat GPT moment, where you are, wow, never see anything like this, I think you have not used planning algorithms, many people will have a kind of AI agent, wow, I couldn't imagine the AI agent doing good, so I've run live demos where something failed, and the AI agent rerouted around the failures, I've actually had quite a few of those more and what, wow, I can't believe my AI system just did that autonomously. But one example that I adapted from a hugging GPT paper, you know, you say, please generate an image where girls read a book, and they post the same as the boy in the image, for example, that JPEG, and please describe the new image review boy. So given example like this, today with AI agents who can kind of decide, first thing I need to do is determine the pose of the boy, then you know, find the right model maybe on hugging face to extract the pose, then next, you need to find the post image model to synthesize a picture of a girl, as following the instructions, then use image detects, and then finally use text and speech, and today we're actually agents that I don't want to say they work reliably, you know, they're kind of finicky, they don't always work, but when it works it's actually pretty amazing, but with agent to groups, sometimes you can recover from earlier failures as well. So I find myself already using research agents for some of my work, where I'll, one piece of research, but I don't feel like, you know, Googling myself and spend long time, like she's sent to the research agent, come back in a few minutes and see what is coming up with, and it sometimes works, sometimes does it, right, but that's already a part of my personal work, though. The final design pattern, multi-agent collaboration, this one, those funny things, but it works much better than you might think, but on the left is a screenshot from a paper called chat dev, which is completely open, which is actually open source. Many of you saw the, you know, flashy social media announcements of demo of a devin, chat dev is open source, it runs on my laptop, and what chat dev does is the example of a multi-agent system where you prompt one LOM to sometimes act like the CEO of a software engine company, sometimes act like a designer, sometimes as a product manager, sometimes act like a tester, and this flock of agents that you built by prompting an LOM to tell them, you're now a CEO, you're now software engineer. They collaborate, have an extended conversation so that if you tell it, please develop a game, develop a Goldmoke game, they'll actually spend you know, a few minutes writing code, testing it, iterating, and then generate like surprisingly complex programs. It doesn't always work, you know, I've used it, sometimes it doesn't work, sometimes it's amazing, but this technology is really getting better. And just one of the design patterns, it turns out that multi-agent debate where you have different agents, you know, for example, it could be have chat GPT and Gemini debate each other, that actually results in better performance as well. So getting multiple similar to air agents work together has been a powerful design pattern as well. So just to summarize, I think these are the patterns I've seen, and I think that if we were to use these patterns, you know, in our work, a lot of us can get a practice as we do quite quickly. And I think that agentic reasoning design patterns are going to be important. This is my small slide. I expected the set of tasks that I could do will expand dramatically this year because of agentic workflows. And one thing that's actually difficult people get used to is when we prompt an LM, we want to respond right away. In fact, a decade ago, when I was, you know, having discussions at Google on a bigger bot's search, type in long prompt. One of the reasons, you know, I failed to push successfully for that was because when you do a web search, you want to respond back in half a second, right? That's just human nature. We like that instant grab instant feedback. But for a lot of the agent workflows, I think we'll need to learn to dedicate the task in AI agents and patiently wait minutes, maybe even hours to for response. But just like I've seen a lot of novice managers delegate something to someone and they check in five minutes later, right? And that's not productive. I think we need to, it's really difficult. We need to do that with some of our AI agents as well. I thought I heard some last. And then one of the important and fast token generators is important because with these agentic workflows, we're iterating over and over. So the LM is generating tokens for the LM to read. So being a generate tokens way faster than any human to read is fantastic. I think that generating more tokens really quickly from even a slightly lower quality LM might give good results compared to slower tokens from a better LM, maybe. It's a little bit controversial because it may let you go around this loop a lot more times, kind of like the results I show with GPDC and an agent architecture on the first slide. And Candlely, I'm really looking forward to car 5 and car 4 and GPD 5 and Gemini 2.0 and all these other wonderful models in the NPR building. And part of me feels like if you're looking forward to running your thing on GPD 5.0 shot, you know, you may really get closer to that level performance on some applications than you might think with agenting reasoning, but on an early model. I think this is an important trend. And honestly, the path to AI feels like a journey rather than a destination, but I think the concept of agent workflows could help us take a small step forward on this very long journey. Thank you.